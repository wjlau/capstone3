{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "classified-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-joint",
   "metadata": {},
   "source": [
    "## Request the webpage's raw HTML and store into MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-target",
   "metadata": {},
   "source": [
    "In order to get each player's career \"per game\" stats, we need to iterate through the alphabet and individually click on each player's name. This may be messy to do given that at the end of each alphabet, we must go back to the player directory landing page and click the next letter. Instead - lets iterate through the alphabet (links are consistent with the /'letter' changing i.e. https://www.basketball-reference.com/players/a/) and grab the list of hyperlinks per alphabet and then iterate through those individual player links to get the html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adverse-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_directory_url = []\n",
    "for letter in string.ascii_lowercase:\n",
    "    player_directory_url.append('https://www.basketball-reference.com/players/'+letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "republican-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_url(directory):\n",
    "    \n",
    "    individual_player_url = []\n",
    "    \n",
    "    for url in directory:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text,'html.parser')\n",
    "        \n",
    "        for row in soup.find_all('tr'):\n",
    "            #skip first row of chart \n",
    "            if row.a != None:\n",
    "                href = row.a.get('href')\n",
    "                individual_player_url.append('https://www.basketball-reference.com'+href)\n",
    "    return individual_player_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "radio-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_z_all_player_urls = get_player_url(player_directory_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-verification",
   "metadata": {},
   "source": [
    "Iterating through all individual basketball player links, getting the html from the page and throwing it into mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "alert-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_mongodb(urls):\n",
    "    client = MongoClient()\n",
    "    db = client.capstone3_bball\n",
    "    players = db.players\n",
    "    \n",
    "    for url in urls:\n",
    "        page = requests.get(url)\n",
    "        players.insert_one({'link':url, 'html':page.text})\n",
    "        \n",
    "    return 'Done!'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "dramatic-threat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done!'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_to_mongodb(a_z_all_player_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ancient-germany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.basketball-reference.com/players/a/abdelal01.html'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_z_all_player_urls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-renewal",
   "metadata": {},
   "source": [
    "If they played in both ABA and NBA - then their NBA score is the second row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "korean-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = requests.get(a_z_all_player_urls[0])\n",
    "soup = BeautifulSoup(c.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "adult-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = soup.find_all(id = 'all_per_game')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "satisfactory-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.find_all('tfoot')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "liable-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize column lists\n",
    "G, GS, MP, FG, FGA, FGPercentage, Three_P, Three_PA, Three_P_Percentage, Two_P, Two_PA, Two_P_Percentage, \\\n",
    "EFG_Percentage, FT, FTA, FT_Percentage, ORB, DRB, TRB, AST, STL, BLK, TOV, PF, PTS = ([], ) * 25\n",
    "\n",
    "#list of columns\n",
    "columns = [G, GS, MP, FG, FGA, FGPercentage, Three_P, Three_PA, Three_P_Percentage, Two_P, Two_PA, Two_P_Percentage, \\\n",
    "EFG_Percentage, FT, FTA, FT_Percentage, ORB, DRB, TRB, AST, STL, BLK, TOV, PF, PTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "measured-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ABA' in x.find_all('tr')[0].text:\n",
    "    for val,col in zip(x.find_all('tr')[1].find_all('td')[4:], columns):\n",
    "        print(val)\n",
    "else:\n",
    "    for i,stat in enumerate(x.find_all('tr')[0].find_all('td')[4:]):\n",
    "        print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-cartoon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "acute-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = []\n",
    "if 'ABA' in x.find_all('tr')[0].text:\n",
    "    for val,col in zip(x.find_all('tr')[1].find_all('td')[4:], columns):\n",
    "        print(val)\n",
    "else:\n",
    "    player_stats = []\n",
    "    for stat in x.find_all('tr')[0].find_all('td')[4:]:\n",
    "        player_stats.append(stat.text)\n",
    "    all_stats.append(player_stats)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "executed-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['256',\n",
       "  '53',\n",
       "  '12.5',\n",
       "  '2.4',\n",
       "  '4.8',\n",
       "  '.502',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '.000',\n",
       "  '2.4',\n",
       "  '4.8',\n",
       "  '.503',\n",
       "  '.502',\n",
       "  '0.9',\n",
       "  '1.3',\n",
       "  '.701',\n",
       "  '1.1',\n",
       "  '2.2',\n",
       "  '3.3',\n",
       "  '0.3',\n",
       "  '0.3',\n",
       "  '0.3',\n",
       "  '1.0',\n",
       "  '1.9',\n",
       "  '5.7']]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-hawaii",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-values",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
